{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T05:59:44.768385Z",
     "start_time": "2024-05-26T05:59:44.765872Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T05:59:45.148460Z",
     "start_time": "2024-05-26T05:59:44.770027Z"
    }
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import torch\n",
    "\n",
    "dataset_name = \"cifar10\"\n",
    "config = {\n",
    "    \"order\": \"01\",\n",
    "    \"task\": \"multiclass\",\n",
    "    \"data\": {\n",
    "        \"batch_size\": 64,\n",
    "        \"size\": 32,\n",
    "    },\n",
    "    \"network\": {\"input_channels\": 3, \"linear_size\": 576, \"num_classes\": 10},\n",
    "    \"train\": {\n",
    "        \"criterion\": torch.nn.CrossEntropyLoss(),\n",
    "        \"checkpoint_save_dir\": \"checkpoints\",\n",
    "        \"epochs\": 50,\n",
    "        \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T05:59:45.196302Z",
     "start_time": "2024-05-26T05:59:45.185431Z"
    }
   },
   "outputs": [],
   "source": [
    "ORDER = config[\"order\"]\n",
    "SIZE = config[\"data\"][\"size\"]\n",
    "TASK = config[\"task\"]\n",
    "NUM_CLASSES = config[\"network\"][\"num_classes\"]\n",
    "EPOCHS = config[\"train\"][\"epochs\"]\n",
    "BATCH_SIZE = config[\"data\"][\"batch_size\"]\n",
    "INPUT_CHANNEL = config[\"network\"][\"input_channels\"]\n",
    "LINEAR_SIZE = config[\"network\"][\"linear_size\"]\n",
    "CRITERION = config[\"train\"][\"criterion\"]\n",
    "DEVICE = config[\"train\"][\"device\"]\n",
    "experiment_name = f\"{ORDER}-{dataset_name}-{SIZE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T05:59:45.198642Z",
     "start_time": "2024-05-26T05:59:45.197092Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_save_dir = join(config[\"train\"][\"checkpoint_save_dir\"], experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T05:59:45.666550Z",
     "start_time": "2024-05-26T05:59:45.199085Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(\n",
    "        \"./data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([transforms.ToTensor()]),\n",
    "    ),\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(\n",
    "        \"./data\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([transforms.ToTensor()]),\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T05:59:45.696564Z",
     "start_time": "2024-05-26T05:59:45.667408Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import lenet_models\n",
    "\n",
    "\n",
    "def get_optimizers_dict(model_dict):\n",
    "    \"\"\"\n",
    "    Get a dictionary of optimizers for the models.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        model_name: torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        for model_name, model in model_dict.items()\n",
    "    }\n",
    "\n",
    "\n",
    "def get_scheduler_dict(optimizer_dict):\n",
    "    \"\"\"\n",
    "    Get a dictionary of schedulers for the optimizers.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        model_name: ExponentialLR(optimizer, gamma=0.9)\n",
    "        for model_name, optimizer in optimizer_dict.items()\n",
    "    }\n",
    "\n",
    "\n",
    "model_dict = lenet_models.get_constant_model_dict(INPUT_CHANNEL, NUM_CLASSES, LINEAR_SIZE)\n",
    "optimizers_dict = get_optimizers_dict(model_dict)\n",
    "schedulers_dict = get_scheduler_dict(optimizers_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T05:59:45.698921Z",
     "start_time": "2024-05-26T05:59:45.697165Z"
    }
   },
   "outputs": [],
   "source": [
    "history_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-26T05:59:45.699507Z"
    }
   },
   "outputs": [],
   "source": [
    "from tcnn.utils.experiment.train import train_and_test_model\n",
    "\n",
    "for model_name, model in model_dict.items():\n",
    "    print(f\"Training model {model_name}\")\n",
    "    history_dict[model_name] = train_and_test_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        CRITERION,\n",
    "        optimizers_dict[model_name],\n",
    "        scheduler=schedulers_dict[model_name],\n",
    "        epochs=EPOCHS,\n",
    "        save_checkpoint=True,\n",
    "        save_checkpoint_interval=1,\n",
    "        checkpoint_save_dir=join(checkpoint_save_dir, model_name),\n",
    "        task=TASK,\n",
    "    )\n",
    "    print(\"***\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcnn.utils.experiment.plot import plot_history\n",
    "\n",
    "for model_name, history in history_dict.items():\n",
    "    print(f\"Model {model_name} history:\")\n",
    "    plot_history(history, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "input_shape = (BATCH_SIZE, 3, SIZE, SIZE)\n",
    "input_tensor = torch.randn(input_shape).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchprofile\n",
    "from tcnn.utils.experiment.model import count_parameters\n",
    "from tcnn.utils.experiment.train import eval_model\n",
    "\n",
    "result = dict()\n",
    "for model_name, model in model_dict.items():\n",
    "    print(f\"Evaluating model {model_name}\")\n",
    "    result[model_name] = dict()\n",
    "    result[model_name][\"macs\"] = torchprofile.profile_macs(model, input_tensor)\n",
    "    result[model_name][\"params\"] = count_parameters(model)\n",
    "    result[model_name][\"performance\"] = eval_model(model, test_loader, CRITERION, TASK)\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    print(\"***\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcnn.utils.experiment.plot import plot_history_dict\n",
    "\n",
    "plot_history_dict(history_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcnn.utils.experiment.log import show_test_result\n",
    "\n",
    "show_test_result(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
