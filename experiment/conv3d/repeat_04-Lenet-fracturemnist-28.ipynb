{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat Experiment \n",
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcnn.utils.experiment.repeat import repeat_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from config.config import load_config28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"fracturemnist3d\"\n",
    "config = load_config28(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORDER = config[\"order\"]\n",
    "SIZE = config[\"data\"][\"size\"]\n",
    "TASK = config[\"task\"]\n",
    "NUM_CLASSES = config[\"network\"][\"num_classes\"]\n",
    "EPOCHS = config[\"train\"][\"epochs\"]\n",
    "BATCH_SIZE = config[\"data\"][\"batch_size\"]\n",
    "INPUT_CHANNEL = config[\"network\"][\"input_channels\"]\n",
    "LINEAR_SIZE = config[\"network\"][\"linear_size\"]\n",
    "CRITERION = config[\"train\"][\"criterion\"]\n",
    "DEVICE = config[\"train\"][\"device\"]\n",
    "NUM_EXPERIMENTS = config[\"repeat\"][\"num_experiments\"]\n",
    "EPOCHS_PER_EXPERIMENT = config[\"repeat\"][\"epochs_per_experiemnt\"]\n",
    "experiment_name = (\n",
    "    f\"repeat-{ORDER}-{dataset_name}-{SIZE}-{NUM_EXPERIMENTS}-{EPOCHS_PER_EXPERIMENT}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_save_dir = join(config[\"train\"][\"checkpoint_save_dir\"], experiment_name)\n",
    "log_save_dir = join(config[\"repeat\"][\"log_save_dir\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_load import get_dataset, get_reset_dataloader\n",
    "\n",
    "train_dataset, test_dataset = get_dataset(dataset_name, BATCH_SIZE, SIZE, TASK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reset dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_dataloader = get_reset_dataloader(TASK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcnn.utils.experiment.model import get_optimizers_medmnist, get_schedulers_medmnist\n",
    "import lenet_models\n",
    "import lenet_models_binary\n",
    "\n",
    "if TASK == \"multiclass\":\n",
    "    model_dict = lenet_models.get_model_dict(INPUT_CHANNEL, NUM_CLASSES, LINEAR_SIZE)\n",
    "    print(\"Loaded multiclass model with {} classes\".format(NUM_CLASSES))\n",
    "elif TASK == \"binary\":\n",
    "    model_dict = lenet_models_binary.get_model_dict(INPUT_CHANNEL, LINEAR_SIZE)\n",
    "    print(\"Loaded binary model\")\n",
    "\n",
    "def_optimizer = get_optimizers_medmnist\n",
    "def_scheduler = get_schedulers_medmnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define result dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "results = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## repeat experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in model_dict.items():\n",
    "    print(\"Traing model: \", model_name)\n",
    "    results[model_name] = repeat_experiment(\n",
    "        model,\n",
    "        [train_dataset, test_dataset],\n",
    "        reset_dataloader,\n",
    "        BATCH_SIZE,\n",
    "        CRITERION,\n",
    "        def_optimizer,\n",
    "        def_scheduler,\n",
    "        NUM_EXPERIMENTS,\n",
    "        EPOCHS_PER_EXPERIMENT,\n",
    "        experiment_name + \"-\" + model_name,\n",
    "        checkpoint_save=True,\n",
    "        checkpoint_save_dir=checkpoint_save_dir,\n",
    "        task=TASK,\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    print(\"***\" * 10 + f\"{model_name} done\" + \"***\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcnn.utils.experiment.log import show_repeat_result, save_result\n",
    "\n",
    "show_repeat_result(results)\n",
    "save_result(results, save_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcnn.utils.experiment.plot import plot_experiment_errorbar\n",
    "\n",
    "plot_experiment_errorbar(\n",
    "    results, metric_key=\"accuracy\", baseline_key=\"lenet\", ylabel=\"Accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_experiment_errorbar(\n",
    "    results, metric_key=\"accuracy\", baseline_key=\"lenet_relu\", ylabel=\"Accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_experiment_errorbar(\n",
    "    results, metric_key=\"auc_score\", baseline_key=\"lenet\", ylabel=\"AUC Score\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_experiment_errorbar(\n",
    "    results, metric_key=\"auc_score\", baseline_key=\"lenet_relu\", ylabel=\"AUC Score\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_experiment_errorbar(\n",
    "    results, metric_key=\"f1\", baseline_key=\"lenet\", ylabel=\"F1 Score\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_experiment_errorbar(\n",
    "    results, metric_key=\"f1\", baseline_key=\"lenet_relu\", ylabel=\"F1 Score\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "limingbo_mmpnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
