{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat Experiment \n",
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcnn.utils.experiment.repeat import repeat_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "dataset_name = \"speechcommand\"\n",
    "config = {\n",
    "    \"order\": \"03\",\n",
    "    \"task\": \"multiclass\",\n",
    "    \"data\": {\n",
    "        \"batch_size\": 32,\n",
    "        \"size\": 8000,\n",
    "    },\n",
    "    \"network\": {\n",
    "        \"input_channels\": 1,\n",
    "        \"linear_size\": 31680,\n",
    "        \"num_classes\": 35,\n",
    "        \"first_layer_kernel_size\": 80,\n",
    "        \"second_layer_kernel_size\": 3,\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"criterion\": torch.nn.CrossEntropyLoss(),\n",
    "        \"checkpoint_save_dir\": \"checkpoints\",\n",
    "        \"epochs\": 100,\n",
    "        \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    },\n",
    "    \"repeat\": {\"num_experiments\": 5, \"epochs_per_experiemnt\": 100, \"log_save_dir\": \"logs\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORDER = config[\"order\"]\n",
    "SIZE = config[\"data\"][\"size\"]\n",
    "TASK = config[\"task\"]\n",
    "NUM_CLASSES = config[\"network\"][\"num_classes\"]\n",
    "EPOCHS = config[\"train\"][\"epochs\"]\n",
    "BATCH_SIZE = config[\"data\"][\"batch_size\"]\n",
    "INPUT_CHANNEL = config[\"network\"][\"input_channels\"]\n",
    "LINEAR_SIZE = config[\"network\"][\"linear_size\"]\n",
    "CRITERION = config[\"train\"][\"criterion\"]\n",
    "DEVICE = config[\"train\"][\"device\"]\n",
    "NUM_EXPERIMENTS = config[\"repeat\"][\"num_experiments\"]\n",
    "EPOCHS_PER_EXPERIMENT = config[\"repeat\"][\"epochs_per_experiemnt\"]\n",
    "experiment_name = (\n",
    "    f\"repeat-{ORDER}-{dataset_name}-{SIZE}-{NUM_EXPERIMENTS}-{EPOCHS_PER_EXPERIMENT}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_save_dir = join(config[\"train\"][\"checkpoint_save_dir\"], experiment_name)\n",
    "log_save_dir = join(config[\"repeat\"][\"log_save_dir\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "\n",
    "train_dataset = torchaudio.datasets.SPEECHCOMMANDS(\n",
    "    f\"./data/\",\n",
    "    download=True,\n",
    "    subset=\"training\",\n",
    ")\n",
    "test_dataset = torchaudio.datasets.SPEECHCOMMANDS(\n",
    "    f\"./data/\",\n",
    "    download=True,\n",
    "    subset=\"testing\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reset dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_index(word, labels):\n",
    "    \"\"\"\n",
    "    Convert a label word to its corresponding index.\n",
    "\n",
    "    Args:\n",
    "        word (str): The label word.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The index of the label.\n",
    "\n",
    "    \"\"\"\n",
    "    return torch.tensor(labels.index(word))\n",
    "\n",
    "\n",
    "def pad_sequence(batch):\n",
    "    \"\"\"\n",
    "    Pad the sequences in a batch with zeros to make them the same length.\n",
    "\n",
    "    Args:\n",
    "        batch (list): A list of tensors representing the sequences.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The padded batch of sequences.\n",
    "\n",
    "    \"\"\"\n",
    "    batch = [item.t() for item in batch]\n",
    "    batch = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=0.0)\n",
    "    return batch.permute(0, 2, 1)\n",
    "\n",
    "\n",
    "def collate_fn_outside(transform, labels):\n",
    "    \"\"\"\n",
    "    Collate function for the data loader.\n",
    "\n",
    "    Args:\n",
    "        transform (callable): A function to transform the waveform.\n",
    "        labels (list): A list of labels.\n",
    "\n",
    "    Returns:\n",
    "        callable: A collate function for the data loader.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def collate_fn_inside(batch):\n",
    "        \"\"\"\n",
    "        Collate function for the data loader.\n",
    "\n",
    "        Args:\n",
    "            batch (list): A list of data tuples.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing the batched tensors and targets.\n",
    "\n",
    "        \"\"\"\n",
    "        tensors, targets = [], []\n",
    "\n",
    "        for waveform, _, label, *_ in batch:\n",
    "            waveform = transform(waveform)\n",
    "            tensors += [waveform]\n",
    "            targets += [label_to_index(label, labels)]\n",
    "\n",
    "        tensors = pad_sequence(tensors)\n",
    "        targets = torch.stack(targets)\n",
    "\n",
    "        return tensors, targets\n",
    "\n",
    "    return collate_fn_inside\n",
    "\n",
    "\n",
    "def reset_dataloader(dataset, batch_size, shuffle):\n",
    "    waveform, sample_rate, _, _, _ = dataset[0]\n",
    "    new_sample_rate = 8000\n",
    "    transform = torchaudio.transforms.Resample(\n",
    "        orig_freq=sample_rate, new_freq=new_sample_rate\n",
    "    )\n",
    "    transformed = transform(waveform)\n",
    "\n",
    "    labels = sorted(list(set(datapoint[2] for datapoint in dataset)))\n",
    "    collate_fn = collate_fn_outside(transform, labels)\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=shuffle,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lenet_models\n",
    "\n",
    "model_dict = lenet_models.get_model_dict(INPUT_CHANNEL, NUM_CLASSES, LINEAR_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def def_optimizer(model):\n",
    "    return torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "def def_scheduler(optimizer):\n",
    "    return torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define result dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "results = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## repeat experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in model_dict.items():\n",
    "    print(\"Traing model: \", model_name)\n",
    "    results[model_name] = repeat_experiment(\n",
    "        model,\n",
    "        [train_dataset, test_dataset],\n",
    "        reset_dataloader,\n",
    "        BATCH_SIZE,\n",
    "        CRITERION,\n",
    "        def_optimizer,\n",
    "        def_scheduler,\n",
    "        NUM_EXPERIMENTS,\n",
    "        EPOCHS_PER_EXPERIMENT,\n",
    "        experiment_name + \"-\" + model_name,\n",
    "        checkpoint_save=True,\n",
    "        checkpoint_save_dir=checkpoint_save_dir,\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    print(\"***\" * 10 + f\"{model_name} done\" + \"***\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcnn.utils.experiment.log import show_repeat_result, save_result\n",
    "\n",
    "show_repeat_result(results)\n",
    "save_result(results, save_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tcnn.utils.experiment.plot import plot_experiment_errorbar\n",
    "\n",
    "# plot_experiment_errorbar(\n",
    "#     results, metric_key=\"accuracy\", baseline_key=\"lenet\", ylabel=\"Accuracy\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_experiment_errorbar(\n",
    "#     results, metric_key=\"accuracy\", baseline_key=\"lenet_relu\", ylabel=\"Accuracy\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_experiment_errorbar(\n",
    "#     results, metric_key=\"auc_score\", baseline_key=\"lenet\", ylabel=\"AUC Score\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_experiment_errorbar(\n",
    "#     results, metric_key=\"auc_score\", baseline_key=\"lenet_relu\", ylabel=\"AUC Score\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_experiment_errorbar(\n",
    "#     results, metric_key=\"f1\", baseline_key=\"lenet\", ylabel=\"F1 Score\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_experiment_errorbar(\n",
    "#     results, metric_key=\"f1\", baseline_key=\"lenet_relu\", ylabel=\"F1 Score\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
