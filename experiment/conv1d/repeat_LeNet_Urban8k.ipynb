{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat Experiment \n",
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcnn.utils.experiment.repeat import repeat_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import torch\n",
    "\n",
    "dataset_name = \"urban8k\"\n",
    "config = {\n",
    "    \"order\": \"01\",\n",
    "    \"task\": \"multiclass\",\n",
    "    \"data\": {\n",
    "        \"batch_size\": 32,\n",
    "        \"size\": 32000,\n",
    "    },\n",
    "    \"network\": {\"input_channels\": 1, \"linear_size\": 127680, \"num_classes\": 10},\n",
    "    \"train\": {\n",
    "        \"criterion\": torch.nn.CrossEntropyLoss(),\n",
    "        \"checkpoint_save_dir\": \"checkpoints\",\n",
    "        \"epochs\": 200,\n",
    "        \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    },\n",
    "    \"repeat\": {\"num_experiments\": 5, \"epochs_per_experiemnt\": 200, \"log_save_dir\": \"logs\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORDER = config[\"order\"]\n",
    "SIZE = config[\"data\"][\"size\"]\n",
    "TASK = config[\"task\"]\n",
    "NUM_CLASSES = config[\"network\"][\"num_classes\"]\n",
    "EPOCHS = config[\"train\"][\"epochs\"]\n",
    "BATCH_SIZE = config[\"data\"][\"batch_size\"]\n",
    "INPUT_CHANNEL = config[\"network\"][\"input_channels\"]\n",
    "LINEAR_SIZE = config[\"network\"][\"linear_size\"]\n",
    "CRITERION = config[\"train\"][\"criterion\"]\n",
    "DEVICE = config[\"train\"][\"device\"]\n",
    "NUM_EXPERIMENTS = config[\"repeat\"][\"num_experiments\"]\n",
    "EPOCHS_PER_EXPERIMENT = config[\"repeat\"][\"epochs_per_experiemnt\"]\n",
    "experiment_name = (\n",
    "    f\"repeat-{ORDER}-{dataset_name}-{SIZE}-{NUM_EXPERIMENTS}-{EPOCHS_PER_EXPERIMENT}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_save_dir = join(config[\"train\"][\"checkpoint_save_dir\"], experiment_name)\n",
    "log_save_dir = join(config[\"repeat\"][\"log_save_dir\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcnn.utils.simulation.dataset.urban_sound_8k import UrbanSound8K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "urban_sound_dataset = UrbanSound8K()\n",
    "x, y = urban_sound_dataset.get_all_data()\n",
    "\n",
    "x = np.transpose(x, (0, 2, 1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=2024\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Loading UrbanSound8K dataset:\")\n",
    "print(f\"Train set size: {x_train.shape[0]} Training set shape: { x_train.shape}\")\n",
    "print(f\"Test set size: {x_test.shape[0]} Test set shape: { x_test.shape}\")\n",
    "print(\"done!\")\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reset dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_dataloader(dataset, batch_size, shuffle=True):\n",
    "    return torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lenet_models\n",
    "\n",
    "model_dict = lenet_models.get_model_dict(INPUT_CHANNEL, NUM_CLASSES, LINEAR_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau  # type: ignore\n",
    "\n",
    "\n",
    "def def_optimizer(model):\n",
    "    return torch.optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "def def_scheduler(optimizer):\n",
    "    return ReduceLROnPlateau(\n",
    "        optimizer, mode=\"max\", factor=0.5, patience=10, min_lr=0.0001, verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define result dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "results = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## repeat experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in model_dict.items():\n",
    "    print(\"Traing model: \", model_name)\n",
    "    results[model_name] = repeat_experiment(\n",
    "        model,\n",
    "        [train_dataset, test_dataset],\n",
    "        reset_dataloader,\n",
    "        BATCH_SIZE,\n",
    "        CRITERION,\n",
    "        def_optimizer,\n",
    "        def_scheduler,\n",
    "        NUM_EXPERIMENTS,\n",
    "        EPOCHS_PER_EXPERIMENT,\n",
    "        experiment_name + \"-\" + model_name,\n",
    "        checkpoint_save=True,\n",
    "        checkpoint_save_dir=checkpoint_save_dir,\n",
    "        scheduler_sign=\"val_acc\",\n",
    "    \n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    print(\"***\" * 10 + f\"{model_name} done\" + \"***\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcnn.utils.experiment.log import show_repeat_result, save_result\n",
    "\n",
    "show_repeat_result(results)\n",
    "save_result(results, save_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tcnn.utils.experiment.plot import plot_experiment_errorbar\n",
    "\n",
    "# plot_experiment_errorbar(\n",
    "#     results, metric_key=\"accuracy\", baseline_key=\"lenet\", ylabel=\"Accuracy\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_experiment_errorbar(\n",
    "#     results, metric_key=\"accuracy\", baseline_key=\"lenet_relu\", ylabel=\"Accuracy\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_experiment_errorbar(\n",
    "#     results, metric_key=\"auc_score\", baseline_key=\"lenet\", ylabel=\"AUC Score\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_experiment_errorbar(\n",
    "#     results, metric_key=\"auc_score\", baseline_key=\"lenet_relu\", ylabel=\"AUC Score\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_experiment_errorbar(\n",
    "#     results, metric_key=\"f1\", baseline_key=\"lenet\", ylabel=\"F1 Score\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_experiment_errorbar(\n",
    "#     results, metric_key=\"f1\", baseline_key=\"lenet_relu\", ylabel=\"F1 Score\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
